# -*- coding: utf-8 -*-
import os
import json
import asyncio
from typing import Dict, Any, List

from utils.create_session_dir import create_session_output_dir
from utils.format_execution_result import format_execution_result
from utils.extract_code import extract_code_from_response
from utils.llm_helper import LLMHelper
from utils.code_executor import CodeExecutor
from config.llm_config import LLMConfig
from prompts import data_analysis_system_prompt

class DataAnalysisAgent:
    def __init__(self, llm_config: LLMConfig = None, output_dir: str = "outputs", max_rounds: int = 10):
        self.config = llm_config or LLMConfig()
        self.llm = LLMHelper(self.config)
        self.base_output_dir = output_dir
        self.max_rounds = max_rounds
        self.reset()

    def _process_response(self, response: str) -> Dict[str, Any]:
        print("\n--- Processing LLM Response ---")
        try:
            yaml_data = self.llm.parse_yaml_response(response)
            action = yaml_data.get('action', 'generate_code')
            print(f"Action: {action}")

            if action == 'analysis_complete':
                print("Analysis complete action detected.")
                final_report_content = yaml_data.get('final_report', '')
                final_report = {
                    "text": final_report_content,
                    "images": self.generated_images
                }
                return {'action': 'analysis_complete', 'continue': False, 'final_report': final_report}

            if action == 'generate_code':
                code = yaml_data.get('code', '') or extract_code_from_response(response)
                if code:
                    print(f"Code to execute:\n{code}")
                    result = self.executor.execute_code(code)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç”Ÿæˆï¼Œå¹¶æå–ç›¸å¯¹URLè·¯å¾„
                    if result.get("success") and "IMAGE_PATH:" in result.get("output", ""):
                        for line in result["output"].splitlines():
                            if line.startswith("IMAGE_PATH:"):
                                path = line.split(":", 1)[1].strip()
                                image_path = os.path.relpath(path, self.base_output_dir).replace("\\", "/")
                                self.generated_images.append(image_path)
                                print(f"Image detected and stored: {image_path}")
                                # å°†å›¾ç‰‡è·¯å¾„æ·»åŠ åˆ°ç»“æœä¸­ï¼Œä»¥ä¾¿å‰ç«¯ä½¿ç”¨
                                result['image_url'] = image_path
                    
                    feedback = format_execution_result(result)
                    print(f"Execution feedback:\n{feedback}")
                    return {'action': 'generate_code', 'code': code, 'result': result, 'feedback': feedback, 'continue': True}
                else:
                    return {'action': 'invalid_response', 'error': 'å“åº”ä¸­ç¼ºå°‘å¯æ‰§è¡Œä»£ç ', 'continue': True}
            
            return {'action': action, 'continue': True, 'error': f'Unknown action: {action}'}
        except Exception as e:
            return {'action': 'error', 'error': str(e), 'continue': True}

    async def analyze_stream(self, user_input: str, files: List[str], queue: asyncio.Queue):
        self.reset()
        self.session_output_dir = create_session_output_dir(self.base_output_dir, user_input)
        self.executor = CodeExecutor(self.session_output_dir)
        self.executor.set_variable('session_output_dir', self.session_output_dir)
        
        initial_prompt = f"ç”¨æˆ·éœ€æ±‚: {user_input}"
        if files:
            initial_prompt += f"\næ•°æ®æ–‡ä»¶: {', '.join(files)}"
        
        self.conversation_history.append({'role': 'user', 'content': initial_prompt})
        await queue.put({"type": "log", "content": f"ğŸš€ å¼€å§‹æ•°æ®åˆ†æä»»åŠ¡ï¼Œè¾“å‡ºç›®å½•: {self.session_output_dir}"})

        while self.current_round < self.max_rounds:
            self.current_round += 1
            await queue.put({"type": "log", "content": f"ğŸ”„ ç¬¬ {self.current_round} è½®åˆ†æå¼€å§‹..."})
            
            try:
                notebook_variables = self.executor.get_environment_info()
                # ä½¿ç”¨ .replace() è€Œä¸æ˜¯ .format() æ¥é¿å…ä¸æç¤ºå†…å®¹ä¸­çš„å¤§æ‹¬å·å†²çª
                formatted_system_prompt = data_analysis_system_prompt.replace("{notebook_variables}", str(notebook_variables))
                
                print(f"\n--- Round {self.current_round} ---")
                print(f"System Prompt: {formatted_system_prompt[:200]}...")
                print(f"User Prompt: {self._build_conversation_prompt()}")

                response_stream = self.llm.async_call_stream(
                    prompt=self._build_conversation_prompt(),
                    system_prompt=formatted_system_prompt
                )
                
                full_response = ""
                # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„stepç”¨äºæµå¼æ›´æ–°
                current_step = {
                    "type": "step", "round": self.current_round,
                    "thought": "", "code": "", "execution_result": {}
                }
                await queue.put(current_step)

                async for chunk in response_stream:
                    full_response += chunk
                    current_step["thought"] = full_response # å®æ—¶æ›´æ–°thought
                    await queue.put(current_step)

                process_result = self._process_response(full_response)
                
                parsed_yaml = self.llm.parse_yaml_response(full_response)
                await queue.put({
                    "type": "step", "round": self.current_round,
                    "thought": parsed_yaml.get('thought', ''),
                    "code": process_result.get('code', ''),
                    "execution_result": process_result.get('result', {}),
                })
                
                if not process_result.get('continue', True):
                    await queue.put({"type": "report", "content": process_result.get('final_report')})
                    print("--- Analysis Finished ---")
                    break
                
                self.conversation_history.append({'role': 'assistant', 'content': full_response})
                if process_result.get('feedback'):
                    self.conversation_history.append({'role': 'user', 'content': f"ä»£ç æ‰§è¡Œåé¦ˆ:\n{process_result['feedback']}"})

            except Exception as e:
                error_msg = f"LLMè°ƒç”¨æˆ–å¤„ç†é”™è¯¯: {str(e)}"
                print(f"ERROR in round {self.current_round}: {error_msg}")
                await queue.put({"type": "error", "content": error_msg})
                break

        if self.current_round >= self.max_rounds:
            await queue.put({"type": "log", "content": f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§è½®æ•° ({self.max_rounds})ï¼Œåˆ†æç»“æŸ"})
            await queue.put({"type": "report", "content": {"text": "åˆ†æå› è¾¾åˆ°æœ€å¤§è½®æ•°è€Œä¸­æ­¢ã€‚", "images": self.generated_images}})
        
        await queue.put(None)

    def _build_conversation_prompt(self) -> str:
        return "\n\n".join([f"{msg['role']}: {msg['content']}" for msg in self.conversation_history])

    def reset(self):
        self.conversation_history = []
        self.current_round = 0
        self.session_output_dir = None
        self.executor = None
        self.generated_images = []
